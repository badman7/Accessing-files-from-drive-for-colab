{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLabV3",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+HId0mjVy4HRITEQwbs9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cskarthik7/Accessing-files-from-drive-for-colab/blob/master/DeepLabV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPZ3C02AZOkY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a13f608-1acb-4ab8-d4ed-f1db9e1eee7c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGAWoYnAi5Ar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b6fc853-321d-447d-8a1e-5b3b03e593a5"
      },
      "source": [
        "cd '/content/drive/My Drive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjtBca2QjWOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "e173d62c-979c-4451-a89a-d251c67d184f"
      },
      "source": [
        "!git clone https://github.com/cskarthik7/deeplabv3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deeplabv3'...\n",
            "remote: Enumerating objects: 322, done.\u001b[K\n",
            "remote: Total 322 (delta 0), reused 0 (delta 0), pack-reused 322\u001b[K\n",
            "Receiving objects: 100% (322/322), 258.28 MiB | 12.96 MiB/s, done.\n",
            "Resolving deltas: 100% (192/192), done.\n",
            "Checking out files: 100% (18/18), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lrQsQcHjdpz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6d0d73cf-180f-4ec5-ebbc-c036c83a389e"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKH5FW1YtDds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pycat deeplabv3/model/resnet.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtuYR2Q2_jY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "02bb9aad-7904-435e-8f7e-86d7e2653e2a"
      },
      "source": [
        "%%writefile deeplabv3/model/resnet.py\n",
        "# camera-ready\n",
        "\n",
        "# NOTE! OS: output stride, the ratio of input image resolution to final output resolution (OS16: output size is (img_h/16, img_w/16)) (OS8: output size is (img_h/8, img_w/8))\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "\n",
        "def make_layer(block, in_channels, channels, num_blocks, stride=1, dilation=1):\n",
        "    strides = [stride] + [1]*(num_blocks - 1) # (stride == 2, num_blocks == 4 --> strides == [2, 1, 1, 1])\n",
        "\n",
        "    blocks = []\n",
        "    for stride in strides:\n",
        "        blocks.append(block(in_channels=in_channels, channels=channels, stride=stride, dilation=dilation))\n",
        "        in_channels = block.expansion*channels\n",
        "\n",
        "    layer = nn.Sequential(*blocks) # (*blocks: call with unpacked list entires as arguments)\n",
        "\n",
        "    return layer\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_channels, channels, stride=1, dilation=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "\n",
        "        out_channels = self.expansion*channels\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "        if (stride != 1) or (in_channels != out_channels):\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            self.downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            self.downsample = nn.Sequential()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (x has shape: (batch_size, in_channels, h, w))\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x))) # (shape: (batch_size, channels, h, w) if stride == 1, (batch_size, channels, h/2, w/2) if stride == 2)\n",
        "        out = self.bn2(self.conv2(out)) # (shape: (batch_size, channels, h, w) if stride == 1, (batch_size, channels, h/2, w/2) if stride == 2)\n",
        "\n",
        "        out = out + self.downsample(x) # (shape: (batch_size, channels, h, w) if stride == 1, (batch_size, channels, h/2, w/2) if stride == 2)\n",
        "\n",
        "        out = F.relu(out) # (shape: (batch_size, channels, h, w) if stride == 1, (batch_size, channels, h/2, w/2) if stride == 2)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_channels, channels, stride=1, dilation=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "\n",
        "        out_channels = self.expansion*channels\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, channels, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(channels, out_channels, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        if (stride != 1) or (in_channels != out_channels):\n",
        "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
        "            bn = nn.BatchNorm2d(out_channels)\n",
        "            self.downsample = nn.Sequential(conv, bn)\n",
        "        else:\n",
        "            self.downsample = nn.Sequential()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (x has shape: (batch_size, in_channels, h, w))\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x))) # (shape: (batch_size, channels, h, w))\n",
        "        out = F.relu(self.bn2(self.conv2(out))) # (shape: (batch_size, channels, h, w) if stride == 1, (batch_size, channels, h/2, w/2) if stride == 2)\n",
        "        out = self.bn3(self.conv3(out)) # (shape: (batch_size, out_channels, h, w) if stride == 1, (batch_size, out_channels, h/2, w/2) if stride == 2)\n",
        "\n",
        "        out = out + self.downsample(x) # (shape: (batch_size, out_channels, h, w) if stride == 1, (batch_size, out_channels, h/2, w/2) if stride == 2)\n",
        "\n",
        "        out = F.relu(out) # (shape: (batch_size, out_channels, h, w) if stride == 1, (batch_size, out_channels, h/2, w/2) if stride == 2)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet_Bottleneck_OS16(nn.Module):\n",
        "    def __init__(self, num_layers):\n",
        "        super(ResNet_Bottleneck_OS16, self).__init__()\n",
        "\n",
        "        if num_layers == 50:\n",
        "            resnet = models.resnet50()\n",
        "            # load pretrained model:\n",
        "            resnet.load_state_dict(torch.load(\"deeplabv3/pretrained_models/resnet/resnet50-19c8e357.pth\"))\n",
        "            # remove fully connected layer, avg pool and layer5:\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-3])\n",
        "\n",
        "            print (\"pretrained resnet, 50\")\n",
        "        elif num_layers == 101:\n",
        "            resnet = models.resnet101()\n",
        "            # load pretrained model:\n",
        "            resnet.load_state_dict(torch.load(\"deeplabv3/pretrained_models/resnet/resnet101-5d3b4d8f.pth\"))\n",
        "            # remove fully connected layer, avg pool and layer5:\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-3])\n",
        "\n",
        "            print (\"pretrained resnet, 101\")\n",
        "        elif num_layers == 152:\n",
        "            resnet = models.resnet152()\n",
        "            # load pretrained model:\n",
        "            resnet.load_state_dict(torch.load(\"deeplabv3/pretrained_models/resnet/resnet152-b121ed2d.pth\"))\n",
        "            # remove fully connected layer, avg pool and layer5:\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-3])\n",
        "\n",
        "            print (\"pretrained resnet, 152\")\n",
        "        else:\n",
        "            raise Exception(\"num_layers must be in {50, 101, 152}!\")\n",
        "\n",
        "        self.layer5 = make_layer(Bottleneck, in_channels=4*256, channels=512, num_blocks=3, stride=1, dilation=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (x has shape (batch_size, 3, h, w))\n",
        "\n",
        "        # pass x through (parts of) the pretrained ResNet:\n",
        "        c4 = self.resnet(x) # (shape: (batch_size, 4*256, h/16, w/16)) (it's called c4 since 16 == 2^4)\n",
        "\n",
        "        output = self.layer5(c4) # (shape: (batch_size, 4*512, h/16, w/16))\n",
        "\n",
        "        return output\n",
        "\n",
        "class ResNet_BasicBlock_OS16(nn.Module):\n",
        "    def __init__(self, num_layers):\n",
        "        super(ResNet_BasicBlock_OS16, self).__init__()\n",
        "\n",
        "        if num_layers == 18:\n",
        "            resnet = models.resnet18()\n",
        "            # load pretrained model:\n",
        "            resnet.load_state_dict(torch.load(\"deeplabv3/pretrained_models/resnet/resnet18-5c106cde.pth\"))\n",
        "            # remove fully connected layer, avg pool and layer5:\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-3])\n",
        "\n",
        "            num_blocks = 2\n",
        "            print (\"pretrained resnet, 18\")\n",
        "        elif num_layers == 34:\n",
        "            resnet = models.resnet34()\n",
        "            # load pretrained model:\n",
        "            resnet.load_state_dict(torch.load(\"deeplabv3/pretrained_models/resnet/resnet34-333f7ec4.pth\"))\n",
        "            # remove fully connected layer, avg pool and layer5:\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-3])\n",
        "\n",
        "            num_blocks = 3\n",
        "            print (\"pretrained resnet, 34\")\n",
        "        else:\n",
        "            raise Exception(\"num_layers must be in {18, 34}!\")\n",
        "\n",
        "        self.layer5 = make_layer(BasicBlock, in_channels=256, channels=512, num_blocks=num_blocks, stride=1, dilation=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (x has shape (batch_size, 3, h, w))\n",
        "\n",
        "        # pass x through (parts of) the pretrained ResNet:\n",
        "        c4 = self.resnet(x) # (shape: (batch_size, 256, h/16, w/16)) (it's called c4 since 16 == 2^4)\n",
        "\n",
        "        output = self.layer5(c4) # (shape: (batch_size, 512, h/16, w/16))\n",
        "\n",
        "        return output\n",
        "\n",
        "class ResNet_BasicBlock_OS8(nn.Module):\n",
        "    def __init__(self, num_layers):\n",
        "        super(ResNet_BasicBlock_OS8, self).__init__()\n",
        "\n",
        "        if num_layers == 18:\n",
        "            resnet = models.resnet18()\n",
        "            # load pretrained model:\n",
        "            resnet.load_state_dict(torch.load(\"deeplabv3/pretrained_models/resnet/resnet18-5c106cde.pth\"))\n",
        "            # remove fully connected layer, avg pool, layer4 and layer5:\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-4])\n",
        "\n",
        "            num_blocks_layer_4 = 2\n",
        "            num_blocks_layer_5 = 2\n",
        "            print (\"pretrained resnet, 18\")\n",
        "        elif num_layers == 34:\n",
        "            resnet = models.resnet34()\n",
        "            # load pretrained model:\n",
        "            resnet.load_state_dict(torch.load(\"deeplabv3/pretrained_models/resnet/resnet34-333f7ec4.pth\"))\n",
        "            # remove fully connected layer, avg pool, layer4 and layer5:\n",
        "            self.resnet = nn.Sequential(*list(resnet.children())[:-4])\n",
        "\n",
        "            num_blocks_layer_4 = 6\n",
        "            num_blocks_layer_5 = 3\n",
        "            print (\"pretrained resnet, 34\")\n",
        "        else:\n",
        "            raise Exception(\"num_layers must be in {18, 34}!\")\n",
        "\n",
        "        self.layer4 = make_layer(BasicBlock, in_channels=128, channels=256, num_blocks=num_blocks_layer_4, stride=1, dilation=2)\n",
        "\n",
        "        self.layer5 = make_layer(BasicBlock, in_channels=256, channels=512, num_blocks=num_blocks_layer_5, stride=1, dilation=4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (x has shape (batch_size, 3, h, w))\n",
        "\n",
        "        # pass x through (parts of) the pretrained ResNet:\n",
        "        c3 = self.resnet(x) # (shape: (batch_size, 128, h/8, w/8)) (it's called c3 since 8 == 2^3)\n",
        "\n",
        "        output = self.layer4(c3) # (shape: (batch_size, 256, h/8, w/8))\n",
        "        output = self.layer5(output) # (shape: (batch_size, 512, h/8, w/8))\n",
        "\n",
        "        return output,c3\n",
        "\n",
        "def ResNet18_OS16():\n",
        "    return ResNet_BasicBlock_OS16(num_layers=18)\n",
        "\n",
        "def ResNet34_OS16():\n",
        "    return ResNet_BasicBlock_OS16(num_layers=34)\n",
        "\n",
        "def ResNet50_OS16():\n",
        "    return ResNet_Bottleneck_OS16(num_layers=50)\n",
        "\n",
        "def ResNet101_OS16():\n",
        "    return ResNet_Bottleneck_OS16(num_layers=101)\n",
        "\n",
        "def ResNet152_OS16():\n",
        "    return ResNet_Bottleneck_OS16(num_layers=152)\n",
        "\n",
        "def ResNet18_OS8():\n",
        "    return ResNet_BasicBlock_OS8(num_layers=18)\n",
        "\n",
        "def ResNet34_OS8():\n",
        "    return ResNet_BasicBlock_OS8(num_layers=34)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting deeplabv3/model/resnet.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZJMO6cU_yCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pycat deeplabv3/model/deeplabv3.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8wHRyPtAXyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ab2399b5-4938-416b-ecde-7e3edd982d72"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "abcd.png     deeplabv3\terfnet_pytorch-master.zip\n",
            "cookies.txt  erfnet\toriginal.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5SyvF8P_6cD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d48ea2d-e82f-4e13-bed5-8421df0f504d"
      },
      "source": [
        "%%writefile deeplabv3/model/deeplabv3.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "\n",
        "from resnet import ResNet18_OS16, ResNet34_OS16, ResNet50_OS16, ResNet101_OS16, ResNet152_OS16, ResNet18_OS8, ResNet34_OS8\n",
        "from aspp import ASPP, ASPP_Bottleneck\n",
        "\n",
        "class DeepLabV3(nn.Module):\n",
        "    def __init__(self, model_id, project_dir):\n",
        "        super(DeepLabV3, self).__init__()\n",
        "\n",
        "        self.num_classes = 20\n",
        "\n",
        "        self.model_id = model_id\n",
        "        self.project_dir = project_dir\n",
        "        self.create_model_dirs()\n",
        "\n",
        "        self.resnet = ResNet18_OS8() # NOTE! specify the type of ResNet here\n",
        "        self.aspp = ASPP(num_classes=self.num_classes) # NOTE! if you use ResNet50-152, set self.aspp = ASPP_Bottleneck(num_classes=self.num_classes) instead\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (x has shape (batch_size, 3, h, w))\n",
        "\n",
        "        h = x.size()[2]\n",
        "        w = x.size()[3]\n",
        "\n",
        "        feature_map,conv = self.resnet(x) # (shape: (batch_size, 512, h/16, w/16)) (assuming self.resnet is ResNet18_OS16 or ResNet34_OS16. If self.resnet is ResNet18_OS8 or ResNet34_OS8, it will be (batch_size, 512, h/8, w/8). If self.resnet is ResNet50-152, it will be (batch_size, 4*512, h/16, w/16))\n",
        "\n",
        "        output = self.aspp(feature_map) # (shape: (batch_size, num_classes, h/16, w/16))\n",
        "\n",
        "        output = F.upsample(output, size=(h, w), mode=\"bilinear\") # (shape: (batch_size, num_classes, h, w))\n",
        "\n",
        "        return output,conv\n",
        "\n",
        "    def create_model_dirs(self):\n",
        "        self.logs_dir = self.project_dir + \"/training_logs\"\n",
        "        self.model_dir = self.logs_dir + \"/model_%s\" % self.model_id\n",
        "        self.checkpoints_dir = self.model_dir + \"/checkpoints\"\n",
        "        if not os.path.exists(self.logs_dir):\n",
        "            os.makedirs(self.logs_dir)\n",
        "        if not os.path.exists(self.model_dir):\n",
        "            os.makedirs(self.model_dir)\n",
        "            os.makedirs(self.checkpoints_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting deeplabv3/model/deeplabv3.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TtOeyLxo-00",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a59f3d99-b739-4ab6-bfca-cd77504ba085"
      },
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append(\"deeplabv3\")\n",
        "from datasets import DatasetThnSeq # (this needs to be imported before torch, because cv2 needs to be imported before torch for some reason)\n",
        "\n",
        "sys.path.append(\"deeplabv3/model\")\n",
        "from deeplabv3 import DeepLabV3\n",
        "\n",
        "sys.path.append(\"deeplabv3/utils\")\n",
        "from utils import label_img_to_color\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "network = DeepLabV3(\"eval_seq_thn\", project_dir=\"deeplabv3\").cuda()\n",
        "network.load_state_dict(torch.load(\"deeplabv3/pretrained_models/model_13_2_2_2_epoch_580.pth\"))\n",
        "\n",
        "val_dataset = DatasetThnSeq(thn_data_path=\"deeplabv3/data/thn\")\n",
        "\n",
        "num_val_batches = int(len(val_dataset)/batch_size)\n",
        "print (\"num_val_batches:\", num_val_batches)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
        "                                         batch_size=batch_size, shuffle=False,\n",
        "                                         num_workers=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pretrained resnet, 18\n",
            "num_val_batches: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX-zr60nz_yI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs,img_id=next(iter(val_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piaFGBHbbhe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_semScores(scoresData,shape,numclasses):\n",
        "   \n",
        "    shape = np.insert(shape,2,numclasses)\n",
        "    print(\"Input shape of scores data - \",scoresData.shape)\n",
        "    print(\"Transpose shape as [1,2,0] - \",scoresData.transpose([1,2,0]).shape)\n",
        "    scores_rsz = resize(scoresData.transpose([1,2,0]),shape,order=0,mode='constant',preserve_range=True)\n",
        "    print(\"Resize shape of scoresTranspose to h/8 and w/8 - \",scores_rsz.shape)\n",
        "    \n",
        "    denseLabels = np.argmax(scores_rsz,axis=2)\n",
        "    \n",
        "    scores_flat = np.reshape(scores_rsz.transpose([2,0,1]),[numclasses,-1])\n",
        "    scores_prob = normalize(scores_flat,'l1',axis=0)\n",
        "    \n",
        "    return scores_prob, denseLabels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Ohk7zA_QDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.transform import resize\n",
        "from sklearn.preprocessing import normalize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH9DYOr78QYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "07a4ebc9-738a-4cfd-dca3-16dbcee6c69d"
      },
      "source": [
        "network.eval()\n",
        "with torch.no_grad(): # (corresponds to setting volatile=True in all variables, this is done during inference to reduce memory consumption)\n",
        "        imgs =imgs.cuda() # (shape: (batch_size, 3, img_h, img_w))\n",
        "\n",
        "        outputs,conv5 = network(imgs) # (shape: (batch_size, num_classes, img_h, img_w))\n",
        "        \n",
        "        ########################################################################\n",
        "        # save data for visualization:\n",
        "        ########################################################################\n",
        "        outputs = outputs.data.cpu().numpy()\n",
        "       # print(outputs.shape[2],outputs.shape[3])\n",
        "\n",
        "        scores_prob,denselabels=process_semScores(outputs[0],np.array([outputs.shape[2]//8,outputs.shape[3]//8]),20)\n",
        "        print(\"Scores probability shape is - \",scores_prob.shape)\n",
        "        print(\"Denselabels shape is - \",denselabels.shape)\n",
        "        print(\"Conv5 tensor is - \",conv5.shape)\n",
        "        pred_label_img = denselabels\n",
        "        pred_label_img_color = label_img_to_color(pred_label_img)\n",
        "        plt.imshow(pred_label_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input shape of scores data -  (20, 512, 1024)\n",
            "Transpose shape as [1,2,0] -  (512, 1024, 20)\n",
            "Resize shape of scoresTranspose to h/8 and w/8 -  (64, 128, 20)\n",
            "Scores probability shape is -  (20, 8192)\n",
            "Denselabels shape is -  (64, 128)\n",
            "Conv5 tensor is -  torch.Size([1, 128, 64, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnfNdjO3ZnaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9a2fb42c-3194-4f42-a95d-5470eba6c87c"
      },
      "source": [
        "img = imgs[0] # (shape: (3, img_h, img_w))\n",
        "img = img.data.cpu().numpy()\n",
        "img = np.transpose(img, (1, 2, 0)) # (shape: (img_h, img_w, 3))\n",
        "img = img*np.array([0.229, 0.224, 0.225])\n",
        "img = img + np.array([0.485, 0.456, 0.406])\n",
        "img = img*255.0\n",
        "img = img.astype(np.uint8)\n",
        "plt.imshow(img)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcca71057b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXJwINxMWXep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37e36383-a79e-445a-9745-a66fcea946f6"
      },
      "source": [
        "cv2.imwrite('/content/drive/My Drive/abcd.png',pred_label_img_color)\n",
        "cv2.imwrite('/content/drive/My Drive/original.png',img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-exo09Gc0GJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J67oAMtQz-Uu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "outputId": "4aaac91d-0769-416f-e380-4e769f6481f7"
      },
      "source": [
        "\n",
        "network.eval() # (set in evaluation mode, this affects BatchNorm and dropout)\n",
        "unsorted_img_ids = []\n",
        "for step, (imgs, img_ids) in enumerate(val_loader):\n",
        "    with torch.no_grad(): # (corresponds to setting volatile=True in all variables, this is done during inference to reduce memory consumption)\n",
        "        imgs = Variable(imgs).cuda() # (shape: (batch_size, 3, img_h, img_w))\n",
        "\n",
        "        outputs = network(imgs) # (shape: (batch_size, num_classes, img_h, img_w))\n",
        "        \n",
        "        ########################################################################\n",
        "        # save data for visualization:\n",
        "        ########################################################################\n",
        "        outputs = outputs.data.cpu().numpy() # (shape: (batch_size, num_classes, img_h, img_w))\n",
        "        pred_label_imgs = np.argmax(outputs, axis=1) # (shape: (batch_size, img_h, img_w))\n",
        "        pred_label_imgs = pred_label_imgs.astype(np.uint8)\n",
        "\n",
        "        for i in range(pred_label_imgs.shape[0]):\n",
        "            pred_label_img = pred_label_imgs[i] # (shape: (img_h, img_w))\n",
        "            img_id = img_ids[i]\n",
        "            img = imgs[i] # (shape: (3, img_h, img_w))\n",
        "\n",
        "            img = img.data.cpu().numpy()\n",
        "            img = np.transpose(img, (1, 2, 0)) # (shape: (img_h, img_w, 3))\n",
        "            img = img*np.array([0.229, 0.224, 0.225])\n",
        "            img = img + np.array([0.485, 0.456, 0.406])\n",
        "            img = img*255.0\n",
        "            img = img.astype(np.uint8)\n",
        "\n",
        "            pred_label_img_color = label_img_to_color(pred_label_img)\n",
        "            overlayed_img = 0.35*img + 0.65*pred_label_img_color\n",
        "            overlayed_img = overlayed_img.astype(np.uint8)\n",
        "\n",
        "            img_h = overlayed_img.shape[0]\n",
        "            img_w = overlayed_img.shape[1]\n",
        "\n",
        "            # TODO! do this using network.model_dir instead\n",
        "            cv2.imwrite(network.model_dir + \"/\" + img_id + \".png\", img)\n",
        "            cv2.imwrite(network.model_dir + \"/\" + img_id + \"_pred.png\", pred_label_img_color)\n",
        "            cv2.imwrite(network.model_dir + \"/\" + img_id + \"_overlayed.png\", overlayed_img)\n",
        "            print(network.model_dir + \"/\" + img_id + \".png\")\n",
        "\n",
        "            unsorted_img_ids.append(img_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "deeplabv3/training_logs/model_eval_seq_thn/0000610.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000598.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000609.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000602.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000611.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000600.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000612.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000601.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000617.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000607.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000616.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000603.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000621.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000604.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000622.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000606.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000624.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000623.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000605.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000608.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000627.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000613.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000629.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000614.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000632.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000615.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000640.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000618.png\n",
            "deeplabv3/training_logs/model_eval_seq_thn/0000638.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-bbb4f2f822f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mpred_label_img_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_img_to_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_label_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0moverlayed_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.65\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpred_label_img_color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moverlayed_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverlayed_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/deeplabv3/utils/utils.py\u001b[0m in \u001b[0;36mlabel_img_to_color\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mimg_color\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_to_color\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg_color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}